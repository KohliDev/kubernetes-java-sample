= Kubernetes Java Samples

This project shows different recipes to run a Java EE application using Kubernetes.

== Kubernetes Concepts

Key concepts of Kubernetes are explained below:

. *Pods*: Collocated group of Docker containers that share an IP and storage volume
. *Service*: Single, stable name for a set of pods, also acts as load balancer
. *Replication Controller*: Manages the lifecycle of pods and ensures specified number are running
. *Labels*: Used to organize and select group of objects
. *etcd*: Distributed key-value store used to persist Kubernetes system state
. *Master*: Hosts cluster-level control services, including the API server, scheduler, and controller manager
. *Node*: Docker host running _kubelet_ (node agent) and proxy services
. *Kubelet*: It runs on each node in the cluster and is responsible for node level pod management.

= Kubernetes Installation

We are going to setup single-node cluster using Fedora 24 which can be downloaded from the following link:

http://mirror.0x.sg/fedora/linux/releases/24/Workstation/x86_64/iso/Fedora-Workstation-Live-x86_64-24-1.2.iso[Fedora 24 ISO Image]

. Set fed-master & fed-node information in /etc/hosts
+
[source, text]
----
$ echo "127.0.0.1	fed-master
127.0.0.1	fed-node" >> /etc/hosts
----
+
. Enable Kubernetes Repo:
+
[source, text]
----
yum -y install --enablerepo=updates-testing kubernetes
----
+
. Install etcd and iptables
+
[source, text]
----
yum -y install etcd iptables
----
+

. Disable the firewall and iptables services
+
[source, text]
----
systemctl disable iptables firewalld
systemctl stop iptables firewalld
----
+

. Edit /etc/kubernetes/config
+
[source, text]
----
# Comma separated list of nodes in the etcd cluster
KUBE_MASTER="--master=http://fed-master:8080"

# logging to stderr means we get it in the systemd journal
KUBE_LOGTOSTDERR="--logtostderr=true"

# journal message level, 0 is debug
KUBE_LOG_LEVEL="--v=0"

# Should this cluster be allowed to run privileged docker containers
KUBE_ALLOW_PRIV="--allow-privileged=false"
----
+

. Edit /etc/kubernetes/apiserver to appear as such
+
[source, text]
----
# The address on the local server to listen to.
KUBE_API_ADDRESS="--address=0.0.0.0"

# Comma separated list of nodes in the etcd cluster
KUBE_ETCD_SERVERS="--etcd-servers=http://127.0.0.1:4001"

# Address range to use for services
KUBE_SERVICE_ADDRESSES="--service-cluster-ip-range=10.254.0.0/16"

# Add your own!
KUBE_API_ARGS="--service_account_key_file=/tmp/serviceaccount.key"
----
+

. Edit /etc/kubernetes/controller-manager
+
[source, text]
----
###
# The following values are used to configure the kubernetes controller-manager

# defaults from config and apiserver should be adequate

# Add your own!
KUBE_CONTROLLER_MANAGER_ARGS="--service_account_private_key_file=/tmp/serviceaccount.key"
----
+

. Edit /etc/etcd/etcd.conf
+
[source, text]
----
ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:4001"
----
+

. Create /var/run/kubernetes
+
[source, text]
----
mkdir /var/run/kubernetes
chown kube:kube /var/run/kubernetes
chmod 750 /var/run/kubernetes
----
+

. We need to configure the kubelet on the node, edit /etc/kubernetes/kubelet to appear as such
+
[source, text]
----
###
# Kubernetes kubelet (node) config

# The address for the info server to serve on (set to 0.0.0.0 or "" for all interfaces)
KUBELET_ADDRESS="--address=0.0.0.0"

# You may leave this blank to use the actual hostname
KUBELET_HOSTNAME="--hostname-override=fed-node"

# location of the api-server
KUBELET_API_SERVER="--api-servers=http://fed-master:8080"

# Add your own!
#KUBELET_ARGS=""
----
+

. Start the appropriate master and node services on this VM by creating a shell script start_k8s.sh as shown below
+
[source, text]
----
$ touch start_k8s.sh
$ chmod +x start _k8s.sh
$ vi start_k8s.sh
openssl genrsa -out /tmp/serviceaccount.key 2048
for SERVICES in etcd kube-apiserver kube-controller-manager kube-scheduler kube-proxy kubelet docker; do
        systemctl restart $SERVICES
        systemctl enable $SERVICES
done
$ ./start-k8s.sh 
Generating RSA private key, 2048 bit long modulus
.......+++
.............+++
e is 65537 (0x10001)
----
+

. Create following node.json file on Kubernetes master node
+
[source, text]
----
{
    "apiVersion": "v1",
    "kind": "Node",
    "metadata": {
        "name": "fed-node",
        "labels":{ "name": "fed-node-label"}
    },
    "spec": {
        "externalID": "fed-node"
    }
}
----
+

. Now create a node object internally in your Kubernetes cluster by running
+
[source, text]
----
$ kubectl create -f ./node.json

$ kubectl get nodes
NAME                LABELS              STATUS
fed-node           name=fed-node-label     Unknown
----
+

. Check to make sure now the cluster can see the fed-node on fed-master, and its status changes to Ready.
+
[source, text]
----
kubectl get nodes
NAME                LABELS              STATUS
fed-node          name=fed-node-label     Ready
----
+

Please refer the following link in case more details or help is required for setting up http://kubernetes.io/docs/getting-started-guides/fedora/fedora_manual_config/[Single-Node Fedora Cluster].

= Fedora_k8s_Demo OVA

. If you are going to use the Fedora_k8s_Demo.ova which is provided to you then just import the ova in Virtual box.

. Set the network as "NAT"

. After powering on the VM click on Activities(top left-hand corner) and type terminal in search bar to open the shell.

. Start Kubernetes with help of the shell script start_k8s.sh which pre-exists in the OVA.
+
[source, text]
----
$ cd kubernetes-java-sample/
$ ./start-k8s.sh 
Generating RSA private key, 2048 bit long modulus
.......+++
.............+++
e is 65537 (0x10001)
----

== A Pod with One Container

This section will explain how to start a Pod with one Container. WildFly base Docker image will be used as the Container.

. Start a Pod with WildFly container:
+
[source, text]
----
$ kubectl create -f wildfly-pod.yaml
pod "wildfly-pod" created
----
+
. Get status of the Pod:
+
[source, text]
----
$ kubectl get -w po
NAME          READY     STATUS              RESTARTS   AGE
wildfly-pod   0/1       ContainerCreating   0          6s
NAME          READY     STATUS    RESTARTS   AGE
wildfly-pod   1/1       Running   0          34s
----
+
NOTE: Make sure to wait for the status to change to Running.
+
. Get complete details about the generated Pod (including IP address):
+
[source, text]
----
$ kubectl describe po wildfly-pod
Name:   wildfly-pod
Namespace:  default
Node:   ip-172-20-0-111.us-west-2.compute.internal/172.20.0.111
Start Time: Wed, 28 Sep 2016 15:38:02 -0700
Labels:   name=wildfly
Status:   Running
IP:   10.244.2.4
Controllers:  <none>
Containers:
  wildfly-pod:
    Container ID: docker://cfba313f7ec2c85c3ec7ff62c529973a2042aeaa1ae07026eb98c503442d2953
    Image:    jboss/wildfly
    Image ID:   docker://sha256:4c99bd2cd264d8a1b4b68816736650ca0c3555726c482a16a43cddc4c61df99c
    Port:   8080/TCP
    Requests:
      cpu:    100m
    State:    Running
      Started:    Wed, 28 Sep 2016 15:38:35 -0700
    Ready:    True
    Restart Count:  0
    Volume Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-4e59z (ro)
    Environment Variables:  <none>
Conditions:
  Type    Status
  Initialized   True 
  Ready   True 
  PodScheduled  True 
Volumes:
  default-token-4e59z:
    Type: Secret (a volume populated by a Secret)
    SecretName: default-token-4e59z
QoS Class:  Burstable
Tolerations:  <none>
Events:
  FirstSeen LastSeen  Count From              SubobjectPath     Type    Reason    Message
  --------- --------  ----- ----              -------------     --------  ------    -------
  4m    4m    1 {default-scheduler }            Normal    Scheduled Successfully assigned wildfly-pod to ip-172-20-0-111.us-west-2.compute.internal
  4m    4m    1 {kubelet ip-172-20-0-111.us-west-2.compute.internal}  spec.containers{wildfly-pod}  Normal    Pulling   pulling image "jboss/wildfly"
  3m    3m    1 {kubelet ip-172-20-0-111.us-west-2.compute.internal}  spec.containers{wildfly-pod}  Normal    Pulled    Successfully pulled image "jboss/wildfly"
  3m    3m    1 {kubelet ip-172-20-0-111.us-west-2.compute.internal}  spec.containers{wildfly-pod}  Normal    Created   Created container with docker id cfba313f7ec2; Security:[seccomp=unconfined]
  3m    3m    1 {kubelet ip-172-20-0-111.us-west-2.compute.internal}  spec.containers{wildfly-pod}  Normal    Started   Started container with docker id cfba313f7ec2
----
+
. Check logs of the Pod:
+
[source, text]
----
$ kubectl logs wildfly-pod
=========================================================================

  JBoss Bootstrap Environment

  JBOSS_HOME: /opt/jboss/wildfly

  JAVA: /usr/lib/jvm/java/bin/java

  JAVA_OPTS:  -server -Xms64m -Xmx512m -XX:MetaspaceSize=96M -XX:MaxMetaspaceSize=256m -Djava.net.preferIPv4Stack=true -Djboss.modules.system.pkgs=org.jboss.byteman -Djava.awt.headless=true

=========================================================================

22:38:35,844 INFO  [org.jboss.modules] (main) JBoss Modules version 1.5.2.Final
22:38:36,209 INFO  [org.jboss.msc] (main) JBoss MSC version 1.2.6.Final
22:38:36,295 INFO  [org.jboss.as] (MSC service thread 1-2) WFLYSRV0049: WildFly Full 10.1.0.Final (WildFly Core 2.2.0.Final) starting
22:38:38,367 INFO  [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0039: Creating http management service using socket-binding (management-http)
22:38:38,388 INFO  [org.xnio] (MSC service thread 1-1) XNIO version 3.4.0.Final

. . .

22:38:40,788 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-2) WFLYUT0006: Undertow HTTPS listener https listening on 0.0.0.0:8443
22:38:40,905 INFO  [org.jboss.ws.common.management] (MSC service thread 1-2) JBWS022052: Starting JBossWS 5.1.5.Final (Apache CXF 3.1.6) 
22:38:41,195 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0060: Http management interface listening on http://127.0.0.1:9990/management
22:38:41,197 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0051: Admin console listening on http://127.0.0.1:9990
22:38:41,197 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: WildFly Full 10.1.0.Final (WildFly Core 2.2.0.Final) started in 5888ms - Started 331 of 577 services (393 services are lazy, passive or on-demand)
----
+
. Delete the Pod:
+
[source, text]
----
$ kubectl delete -f wildfly-pod.yaml
pod "wildfly-pod" deleted
----

== A Pod with two Containers

. In this example we will be creating two containers in one pod using json/yaml file. This configuration is generally used to keep the dependent components of your application together but in seperate containers.
+
[source, text]
----
$ kubectl create -f nginx-redis.json 
pod "nginx-redis" created
$ kubectl get pods
NAME          READY     STATUS    RESTARTS   AGE
nginx-redis   2/2       Running   0          5s
----
+

. We can see one pod created above but two containers will be running in the system which can be listed using docker command:
+
[source, text]
----
$ docker ps 
CONTAINER ID        IMAGE                                COMMAND                  CREATED             STATUS              PORTS               NAMES
c89e41dea460        nginx                                "nginx -g 'daemon off"   8 seconds ago       Up 8 seconds                            k8s_nginx.df822a8e_nginx-redis_default_e34d1ae0-bac7-11e6-a326-0800279bf046_75f4d256
fe85d388b2ba        redis                                "docker-entrypoint.sh"   9 seconds ago       Up 8 seconds                            k8s_key-value-store.827e2eb6_nginx-redis_default_e34d1ae0-bac7
----
+

. Delete the pod
+
[source, text]
----
$ kubectl delete -f nginx-redis.json 
pod "nginx-redis" deleted
----
+

== A Replication Controller with Two Replicas of a Pod

This section will explain how to start a https://github.com/kubernetes/kubernetes/blob/master/docs/user-guide/replication-controller.md[Replication Controller] with two replicas of a Pod. Each Pod will have one WildFly container.

. Start a Replication Controller that has two replicas of a pod, each with a WildFly container:
+
[source, text]
----
$ kubectl create -f wildfly-rc.yaml
----
. Get status of the Pods:
+
[source, text]
----
$ kubectl get -w po
NAME               READY     STATUS              RESTARTS   AGE
wildfly-rc-iv1o6   0/1       ContainerCreating   0          3s
wildfly-rc-lbcyq   0/1       ContainerCreating   0          3s
NAME               READY     STATUS    RESTARTS   AGE
wildfly-rc-iv1o6   1/1       Running   0          3s
wildfly-rc-lbcyq   1/1       Running   0         36s
----
+
NOTE: Make sure to wait for the status to change to Running.
+
Note down name of the Pods as "`wildfly-rc-bgtkg`" and "`wildfly-rc-l8fqv`".
+
. Get status of the Replication Controller:
+
[source, text]
----
$ kubectl get rc
NAME         DESIRED   CURRENT   READY     AGE
wildfly-rc   2         2         2         55s
----
+
If multiple Replication Controllers are running then you can query for this specific one using the label:
+
[source, text]
----
$ kubectl get rc -l name=wildfly
NAME         DESIRED   CURRENT   READY     AGE
wildfly-rc   2         2         2         1m
----

=== Rescheduling Pods

Replication Controller ensures that specified number of pod "`replicas`" are running at any one time. If there are too many, the replication controller kills some pods. If there are too few, it starts more.

Lets start a Replication Controller with two replicas of a pod. Delete a Pod and see how a new Pod is automatically rescheduled.

. Get pods:
+
[source, text]
----
$ kubectl get pods
NAME               READY     STATUS    RESTARTS   AGE
wildfly-rc-iv1o6   1/1       Running   0          2m
wildfly-rc-lbcyq   1/1       Running   0          2m
----
+
. Delete a pod:
+
[source, text]
----
$ kubectl delete pod/wildfly-rc-iv1o6
pod "wildfly-rc-iv1o6" deleted
----
+
. Get pods:
+
[source, text]
----
$ kubectl get pods
NAME               READY     STATUS    RESTARTS   AGE
wildfly-rc-lbcyq   1/1       Running   0          3m
wildfly-rc-z3wg3   1/1       Running   0          6s
----
+
See a new pod is now created.

=== Scaling Pods

Replication Controller allows dynamic scaling up and down of Pods.

. Scale up the number of Pods:
+
[source, text]
----
$ kubectl scale --replicas=3 rc wildfly-rc
scaled
----
+
. Check pods:
+
[source, text]
----
$ kubectl get -w pods
NAME               READY     STATUS              RESTARTS   AGE
wildfly-rc-htfj2   1/1       Running             0          1m
wildfly-rc-oq97h   0/1       ContainerCreating   0          26s
wildfly-rc-z3wg3   1/1       Running             0          3m
NAME               READY     STATUS    RESTARTS   AGE
wildfly-rc-oq97h   1/1       Running   0          41s
----
+
Notice a new Pod with the name "`wildfly-rc-oq97h`" is created.
+
. Check RC:
+
[source, text]
----
$ kubectl get rc
NAME         DESIRED   CURRENT   READY     AGE
wildfly-rc   3         3         3         7m
----
+
. Scale down the number of Pods:
+
[source, text]
----
$ kubectl scale --replicas=1 rc wildfly-rc
scaled
----
+
. Check RC:
+
[source, text]
----
$ kubectl get rc
NAME         DESIRED   CURRENT   READY     AGE
wildfly-rc   1         1         1         8m
----
+
. Check pods:
+
[source, text]
----
$ kubectl get pods
NAME               READY     STATUS    RESTARTS   AGE
wildfly-rc-z3wg3   1/1       Running   0          5m
----
+
Notice only one Pod is running now.

=== Delete the Replication Controller

Finally, delete the Replication Controller:

[source, text]
----
$ kubectl delete -f wildfly-rc.yaml
replicationcontroller "wildfly-rc" deleted
----

== Kubernetes Service

In this section we will be creating a nginx pod and then exposing a service for it.

. Create the nginx pod
+
[source, text]
----
$ kubectl create -f nginx-pod.yaml 
deployment "my-nginx" created

$ kubectl get pods
NAME                        READY     STATUS    RESTARTS   AGE
my-nginx-1072136342-f9ese   1/1       Running   0          11s
my-nginx-1072136342-w8bsl   1/1       Running   0          11s
----
+

. Expose the above created nginx pod with help of nginx-service
+
[source, text]
----
$ kubectl create -f nginx-service.yaml 
service "my-nginx" created
$ kubectl get services
NAME         CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
kubernetes   10.254.0.1       <none>        443/TCP   28d
my-nginx     10.254.136.124   <none>        80/TCP    5s

$ kubectl describe service my-nginx
Name:			my-nginx
Namespace:		default
Labels:			run=my-nginx
Selector:		run=my-nginx
Type:			ClusterIP
IP:			10.254.136.124
Port:			<unset>	80/TCP
Endpoints:		172.17.0.2:80,172.17.0.3:80
Session Affinity:	None
No events.
----
+

. Delete the pod and service
+
[source, text]
----
$ kubectl delete -f nginx-pod.yaml 
deployment "my-nginx" deleted
$ kubectl delete -f nginx-service.yaml 
service "my-nginx" deleted
----
+
The nginx server can be accessed inside the VM at http://172.17.0.2:80 or http://172.17.0.3:80 as per your Endpoint IP address.


== Java EE Application deployed in a Pod with one Container (WildFly + H2 in-memory database)

This section will show how to deploy a Java EE application in a Pod with one Container. WildFly, with an in-memory H2 database, will be used as the container.

. Create Java EE 7 sample application Replication Controller:
+
[source, text]
----
$ kubectl create -f javaee7-hol.yaml
replicationcontroller "javaee7-hol" created
----
+
. Get status of the Pod:
+
[source, text]
----
$ kubectl get -w po
NAME                READY     STATUS              RESTARTS   AGE
javaee7-hol-09ups   0/1       ContainerCreating   0          13s
NAME                READY     STATUS    RESTARTS   AGE
javaee7-hol-09ups   1/1       Running   0          36s
----
+
NOTE: Make sure to wait for the status to change to Running.
+
. Get status of the Replication Controller:
+
[source, text]
----
$ kubectl get rc
NAME          DESIRED   CURRENT   READY     AGE
javaee7-hol   1         1         1         11s
----
+
. Get all pods:
+
[source, text]
----
$ kubectl get pods
NAME                READY     STATUS    RESTARTS   AGE
javaee7-hol-e4ezg   1/1       Running   0          24s
----
+
. Get logs:
+
[source, text]
----
$ kubectl logs javaee7-hol-e4ezg
=========================================================================

  JBoss Bootstrap Environment

  JBOSS_HOME: /opt/jboss/wildfly

. . .

23:00:05,516 INFO  [org.jboss.as.ejb3.deployment.processors.EjbJndiBindingsDeploymentUnitProcessor] (MSC service thread 1-2) JNDI bindings for session bean named ShowTimingFacadeREST in deployment unit deployment "movieplex7-1.0-SNAPSHOT.war" are as follows:

  java:global/movieplex7-1.0-SNAPSHOT/ShowTimingFacadeREST!org.javaee7.movieplex7.rest.ShowTimingFacadeREST
  java:app/movieplex7-1.0-SNAPSHOT/ShowTimingFacadeREST!org.javaee7.movieplex7.rest.ShowTimingFacadeREST
  java:module/ShowTimingFacadeREST!org.javaee7.movieplex7.rest.ShowTimingFacadeREST
  java:global/movieplex7-1.0-SNAPSHOT/ShowTimingFacadeREST
  java:app/movieplex7-1.0-SNAPSHOT/ShowTimingFacadeREST
  java:module/ShowTimingFacadeREST

. . .

23:00:12,128 INFO  [org.jboss.as.server] (ServerService Thread Pool -- 37) WFLYSRV0010: Deployed "movieplex7-1.0-SNAPSHOT.war" (runtime-name : "movieplex7-1.0-SNAPSHOT.war")
23:00:12,362 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0060: Http management interface listening on http://127.0.0.1:9990/management
23:00:12,363 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0051: Admin console listening on http://127.0.0.1:9990
23:00:12,363 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: WildFly Full 9.0.0.Final (WildFly Core 1.0.0.Final) started in 14272ms - Started 437 of 607 services (233 services are lazy, passive or on-demand)
----
+
. Expose RC as a Service:
+
[source, text]
----
$ kubectl expose rc javaee7-hol --name=javaee7-webapp --port=8080 --target-port=8080
----
+
. Start proxy:
+
[source, text]
----
$ kubectl proxy
----
+
. Access the application from the inside the VM at: http://127.0.0.1:8001/api/v1/proxy/namespaces/default/services/javaee7-webapp/movieplex7/
+
. Application can also be accessed using the external LB. Get ingress LB address:
+
[source, text]
----
$ kubectl describe service javaee7-webapp
Name:     javaee7-webapp
Namespace:    default
Labels:     name=javaee7-hol
Selector:   name=javaee7-hol
Type:     LoadBalancer
IP:     10.0.127.236
LoadBalancer Ingress: acfadbbb785d011e6afad02cb89b07e4-1679328360.us-west-2.elb.amazonaws.com
Port:     <unset> 8080/TCP
NodePort:   <unset> 30757/TCP
Endpoints:    10.244.0.9:8080
Session Affinity: None
Events:
  FirstSeen LastSeen  Count From      SubobjectPath Type    Reason      Message
  --------- --------  ----- ----      ------------- --------  ------      -------
  4m    4m    1 {service-controller }     Normal    CreatingLoadBalancer  Creating load balancer
  4m    4m    1 {service-controller }     Normal    CreatedLoadBalancer Created load balancer
----
+
. Get the value of `LoadBalancer Ingress` and access the app from inside the VM at http://<IP>:8080/movieplex7.
+
. Delete resources:
+
[source, text]
----
$ kubectl delete rc/javaee7-hol svc/javaee7-webapp
replicationcontroller "javaee7-hol" deleted
service "javaee7-webapp" deleted
----

== Extra Example: Couchbase Service

Pods are ephemeral. IP address assigned to a Pod cannot be relied upon. Kubernetes, Replication Controller in particular, create and destroy Pods dynamically. A _consumer_ Pod cannot rely upon the IP address of a _producer_ Pod.

https://github.com/kubernetes/kubernetes/blob/master/docs/user-guide/services.md[Kubernetes Service] is an abstraction which defines a set of logical Pods. The set of Pods targeted by a Service are determined by labels associated with the Pods.

This section will show how to run a Couchbase service and using a Spring Boot application to write a JSON document to Couchbase.

The order of Service and the targeted Pods does not matter. However Service needs to be started before any other Pods consuming the Service are started.

. Start Couchase RC and Service:
+
[source, text]
----
$ kubectl create -f couchbase-service.yml
service "couchbase-service" created
replicationcontroller "couchbase-rc" created
----
+
. Get status of the Pod:
+
[source, text]
----
$ kubectl get -w pods
NAME                 READY     STATUS              RESTARTS   AGE
couchbase-rc-yl4am   0/1       ContainerCreating   0          13s
NAME                 READY     STATUS    RESTARTS   AGE
couchbase-rc-yl4am   1/1       Running   0          22s
----
+
If multiple pods are running, then the list of pods can be narrowed by specifying labels:
+
[source, text]
----
$ kubectl get pod -l app=couchbase-rc-pod
NAME                 READY     STATUS    RESTARTS   AGE
couchbase-rc-yl4am   1/1       Running   0          2m
----
+
. Get status of the Service:
+
[source, text]
----
$ kubectl get service
NAME                CLUSTER-IP    EXTERNAL-IP   PORT(S)                                AGE
couchbase-service   10.0.38.222   <none>        8091/TCP,8092/TCP,8093/TCP,11210/TCP   1m
kubernetes          10.0.0.1      <none>        443/TCP                                53m
----
+
. Run Java application:
+
[source, text]
----
$ kubectl create -f bootiful-couchbase.yml
job "bootiful-couchbase" created
----
+
. Check the status of Pod:
+
[source, text]
----
$ kubectl get pods
NAME                 READY     STATUS    RESTARTS   AGE
couchbase-rc-vv5ny   1/1       Running   0          4m
  info: 1 completed object(s) was(were) not shown in pods list. Pass --show-all to see all objects.
----
+
. See all the pods:
+
[source, text]
----
$ kubectl get pods --show-all
NAME                       READY     STATUS      RESTARTS   AGE
bootiful-couchbase-m3d8i   0/1       Completed   0          29s
couchbase-rc-yl4am         1/1       Running     0          4m
----
+
. Get logs from pod:
+
[source, text]
----
$ kubectl logs bootiful-couchbase-m3d8i

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.4.0.RELEASE)

2016-09-29 19:21:09.955  INFO 5 --- [           main] org.example.webapp.Application           : Starting Application v1.0-SNAPSHOT on bootiful-couchbase-m3d8i with PID 5 (/maven/bootiful-couchbase.jar started by root in /)
2016-09-29 19:21:09.965  INFO 5 --- [           main] org.example.webapp.Application           : No active profile set, falling back to default profiles: default
2016-09-29 19:21:10.156  INFO 5 --- [           main] s.c.a.AnnotationConfigApplicationContext : Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@4ccabbaa: startup date [Thu Sep 29 19:21:10 UTC 2016]; root of context hierarchy
2016-09-29 19:21:12.314  INFO 5 --- [           main] c.c.client.core.env.CoreEnvironment      : ioPoolSize is less than 3 (1), setting to: 3
2016-09-29 19:21:12.316  INFO 5 --- [           main] c.c.client.core.env.CoreEnvironment      : computationPoolSize is less than 3 (1), setting to: 3
2016-09-29 19:21:12.647  INFO 5 --- [           main] com.couchbase.client.core.CouchbaseCore  : CouchbaseEnvironment: {sslEnabled=false, sslKeystoreFile='null', sslKeystorePassword='null', queryEnabled=false, queryPort=8093, bootstrapHttpEnabled=true, bootstrapCarrierEnabled=true, bootstrapHttpDirectPort=8091, bootstrapHttpSslPort=18091, bootstrapCarrierDirectPort=11210, bootstrapCarrierSslPort=11207, ioPoolSize=3, computationPoolSize=3, responseBufferSize=16384, requestBufferSize=16384, kvServiceEndpoints=1, viewServiceEndpoints=1, queryServiceEndpoints=1, searchServiceEndpoints=1, ioPool=NioEventLoopGroup, coreScheduler=CoreScheduler, eventBus=DefaultEventBus, packageNameAndVersion=couchbase-java-client/2.2.8 (git: 2.2.8, core: 1.2.9), dcpEnabled=false, retryStrategy=BestEffort, maxRequestLifetime=75000, retryDelay=ExponentialDelay{growBy 1.0 MICROSECONDS, powers of 2; lower=100, upper=100000}, reconnectDelay=ExponentialDelay{growBy 1.0 MILLISECONDS, powers of 2; lower=32, upper=4096}, observeIntervalDelay=ExponentialDelay{growBy 1.0 MICROSECONDS, powers of 2; lower=10, upper=100000}, keepAliveInterval=30000, autoreleaseAfter=2000, bufferPoolingEnabled=true, tcpNodelayEnabled=true, mutationTokensEnabled=false, socketConnectTimeout=1000, dcpConnectionBufferSize=20971520, dcpConnectionBufferAckThreshold=0.2, dcpConnectionName=dcp/core-io, callbacksOnIoPool=false, queryTimeout=7500, viewTimeout=7500, kvTimeout=2500, connectTimeout=5000, disconnectTimeout=25000, dnsSrvEnabled=false}
2016-09-29 19:21:13.120  INFO 5 --- [      cb-io-1-1] com.couchbase.client.core.node.Node      : Connected to Node couchbase-service
2016-09-29 19:21:13.265  INFO 5 --- [      cb-io-1-1] com.couchbase.client.core.node.Node      : Disconnected from Node couchbase-service
2016-09-29 19:21:13.874  INFO 5 --- [      cb-io-1-2] com.couchbase.client.core.node.Node      : Connected to Node couchbase-service
2016-09-29 19:21:14.167  INFO 5 --- [-computations-3] c.c.c.core.config.ConfigurationProvider  : Opened bucket books
2016-09-29 19:21:15.516  INFO 5 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
Book{isbn=978-1-4919-1889-0, name=Minecraft Modding with Forge, cost=29.99}
2016-09-29 19:21:16.792  INFO 5 --- [           main] org.example.webapp.Application           : Started Application in 8.021 seconds (JVM running for 8.998)
2016-09-29 19:21:16.805  INFO 5 --- [       Thread-5] s.c.a.AnnotationConfigApplicationContext : Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@4ccabbaa: startup date [Thu Sep 29 19:21:10 UTC 2016]; root of context hierarchy
2016-09-29 19:21:16.808  INFO 5 --- [       Thread-5] o.s.j.e.a.AnnotationMBeanExporter        : Unregistering JMX-exposed beans on shutdown
2016-09-29 19:21:16.824  INFO 5 --- [      cb-io-1-2] com.couchbase.client.core.node.Node      : Disconnected from Node couchbase-service
2016-09-29 19:21:16.826  INFO 5 --- [       Thread-5] c.c.c.core.config.ConfigurationProvider  : Closed bucket books
----
